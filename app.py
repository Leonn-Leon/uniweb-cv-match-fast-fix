import json
from copy import deepcopy
from pathlib import Path

import numpy as np
import pandas as pd
import streamlit as st

from utils.hardcode_data import candidate_names, map_names
from utils.utils import *

if "computed" not in st.session_state:
    st.session_state["computed"] = False


st.title("–ú–∞—Å—Å–æ–≤—ã–π –ø–æ–¥–±–æ—Ä –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ üíº")

# mode = st.select_slider(
#     "–í—ã–±–µ—Ä–µ—Ç–µ —Ç–∏–ø –ø–æ–¥–±–æ—Ä–∞",
#     options=[
#         str(Mode.MASS),
#         str(Mode.PROF),
#     ],
# )

mode = Mode.MASS

if mode == str(Mode.PROF):
    vacancy_df = load_data(path="./data/vacancies.csv")
    selector, config = load_model(config_path="./config/config.yaml")
else:
    # vacancy_df = load_data(path="./data_mass/vacancies.csv")
    selector, config = load_model(config_path="./config/config_mass.yaml")

# vacancies = vacancy_df["–î–æ–ª–∂–Ω–æ—Å—Ç—å"].to_list()

if "df_weights" not in st.session_state:
    features = deepcopy(config["model"]["stage_2"]["ranking_features"])
    info_dict = {"–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∞": [], "–í–µ—Å": []}
    for feature, value in zip(features, config["model"]["stage_2"]["weights"]):
        info_dict["–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∞"].append(
            feature if feature not in map_names else map_names[feature]
        )
        info_dict["–í–µ—Å"].append(round(value, 2))

    df_weights = pd.DataFrame(info_dict)
    st.session_state["df_weights"] = df_weights
if 'current_threshold' not in st.session_state:
    st.session_state['current_threshold'] = config["model"]["stage_2"]["score_threshold"]

with st.sidebar:
    st.header("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è ‚ÑπÔ∏è")
    st.write("–í–µ—Å–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç —Å–∫–æ—Ä–∏–Ω–≥–∞.")
    st.session_state["df_weights"] = st.data_editor(
        st.session_state["df_weights"],
        disabled=["–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∞"],
        hide_index=True,
        # height=423,
        width=300,
    )
    # st.markdown(df_info.to_html(escape=False), unsafe_allow_html=True)

    # Add threshold controls
    st.header("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–¥–±–æ—Ä–∞")
    threshold = st.slider(
        "–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ–Ω—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è",
        min_value=0.0,
        max_value=1.0,
        value=0.5,
        step=0.05,
        help="–ö–∞–Ω–¥–∏–¥–∞—Ç—ã —Å –ø—Ä–æ—Ü–µ–Ω—Ç–æ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –Ω–∏–∂–µ —ç—Ç–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–µ –±—É–¥—É—Ç –ø–æ–∫–∞–∑–∞–Ω—ã"
    )

    # Add apply button for threshold
    if st.button("–ü—Ä–∏–º–µ–Ω–∏—Ç—å –ø–æ—Ä–æ–≥", key="apply_threshold"):
        st.session_state['current_threshold'] = threshold
        st.rerun()

# option = st.selectbox(
#     "–í–∞–∫–∞–Ω—Å–∏–∏",
#     vacancies,
#     index=None,
#     placeholder="–í—ã–±–µ—Ä–µ—Ç–µ –≤–∞–∫–∞–Ω—Å–∏—é...",
# )
vacancy = {}
placeholder_position = "–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä, ¬´–ì–æ—Ä–Ω–æ—Ä–∞–±–æ—á–∏–π¬ª."
vacancy["–î–æ–ª–∂–Ω–æ—Å—Ç—å"] = st.text_input(
    "–î–æ–ª–∂–Ω–æ—Å—Ç—å",
    placeholder=placeholder_position,
    value="",
    help=placeholder_position,
)
vacancy["–î–æ–ª–∂–Ω–æ—Å—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—è"] = vacancy["–î–æ–ª–∂–Ω–æ—Å—Ç—å"]
vacancy["–î–æ–ª–∂–Ω–æ—Å—Ç—å –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è"] = vacancy["–î–æ–ª–∂–Ω–æ—Å—Ç—å"]
placeholder_req = "–ü–µ—Ä–µ—á–∏—Å–ª–∏—Ç–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –∫–∞–Ω–¥–∏–¥–∞—Ç—É, –Ω–∞–ø—Ä–∏–º–µ—Ä ,—É—Ä–æ–≤–µ–Ω—å –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –∏ –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—ã–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏, –æ–±—ä–µ–º –æ–ø—ã—Ç–∞ —Ä–∞–±–æ—Ç—ã, —Ñ–∏–∑–∏—á–µ—Å–∫–∏–µ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã –∏ —Ç–¥."
vacancy["required"] = st.text_area(
    "–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è",
    placeholder=placeholder_req,
    value="",
    help=placeholder_req,
)
placeholder_loc = "–£–∫–∞–∂–∏—Ç–µ –∞–¥—Ä–µ—Å –æ—Å—É—â–µ—Å—Ç–≤–ª–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã, —Ç–∏–ø –∑–∞–Ω—è—Ç–æ—Å—Ç–∏ (–≤–∞—Ö—Ç–æ–≤—ã–π –º–µ—Ç–æ–¥, –ø–æ–ª–Ω–∞—è –∑–∞–Ω—è—Ç–æ—Å—Ç—å, —á–∞—Å—Ç–∏—á–Ω–∞—è –∑–∞–Ω—è—Ç–æ—Å—Ç—å –∏ –¥—Ä.), –∞ —Ç–∞–∫–∂–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –ø–µ—Ä–µ–µ–∑–¥–∞."
vacancy["location"] = st.text_area(
    "–õ–æ–∫–∞—Ü–∏—è –∏ —Ñ–æ—Ä–º–∞—Ç —Ä–∞–±–æ—Ç—ã",
    placeholder=placeholder_loc,
    value="",
    help=placeholder_loc,
)
placeholder_add = "–ü–µ—Ä–µ—á–∏—Å–ª–∏—Ç–µ –Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –∫–∞–Ω–¥–∏–¥–∞—Ç—É, –Ω–∞–ø—Ä–∏–º–µ—Ä, —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –Ω–∞–≤—ã–∫–∏, –æ–ø–∏—Å–∞–Ω–∏–µ –æ–ø—ã—Ç–∞ —Ä–∞–±–æ—Ç—ã, –¥—Ä—É–≥–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞."
vacancy["additional"] = st.text_area(
    "–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è",
    placeholder=placeholder_add,
    value="",
    help=placeholder_add,
)
# salary_feats = st.text_area("–£—Ä–æ–≤–µ–Ω—å –∑–∞—Ä–∞–±–æ—Ç–Ω–æ–π –ø–ª–∞—Ç—ã", placeholder="–í–≤–µ–¥–∏—Ç–µ –∑–∞—Ä–ø–ª–∞—Ç–Ω—É—é –≤–∏–ª–∫—É", value = None)

if st.button("–ü–æ–¥–æ–±—Ä–∞—Ç—å", type="primary"):
    if (
        vacancy["–î–æ–ª–∂–Ω–æ—Å—Ç—å"] != ""
        and vacancy["required"] != ""
        and vacancy["location"] != ""
    ):
        if mode == str(Mode.PROF):
            pass
        else:
            df_cv = load_data(f"./data_mass/candidates.csv")
            df_cv = df_cv.rename(columns={"address": "–ê–¥—Ä–µ—Å"})
        with st.status("–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–∏..."):
            vacancy = selector.preprocess_vacancy(vacancy)
        with st.status("–ü–æ–¥–±–æ—Ä –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤..."):
            if (
                not Path("./tmp_cvs.csv").exists()
                or config["general"]["mode"] == "prod"
            ):
                st.write(f"–ü–µ—Ä–≤–∞—è —Ñ–∞–∑–∞: –∞–Ω–∞–ª–∏–∑ {df_cv.shape[0]} –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤..")
                df_ranked_1st = selector.rank_first_stage(
                    vacancy=vacancy, df_relevant=df_cv.copy()
                )
                st.write(f"–í—Ç–æ—Ä–∞—è —Ñ–∞–∑–∞: –∞–Ω–∞–ª–∏–∑ {df_ranked_1st.shape[0]} –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤..")
                df_ranked_2nd, vacancy_prep, nan_mask = selector.rank_second_stage(
                    vacancy=vacancy,
                    df_relevant=df_ranked_1st.copy(),
                    df_weights=st.session_state["df_weights"],
                    score_threshold_stage_2=threshold
                )
                if config["general"]["mode"] != "prod":
                    df_ranked_2nd.to_csv("./tmp_cvs.csv", index=False)
                    with open("./tmp_vac.json", "w") as f:
                        json.dump(vacancy_prep, f, ensure_ascii=False)
                    np.save("./tmp_mask.npy", nan_mask)
            else:
                df_ranked_2nd = pd.read_csv("./tmp_cvs.csv")
                with open("./tmp_vac.json", "r") as f:
                    vacancy_prep = json.load(f)
                nan_mask = np.load("./tmp_mask.npy")

            data_cv = df2dict(df_ranked_2nd)
            st.session_state["computed"] = True
            st.write(f"–í—ã–±—Ä–∞–Ω–æ {df_ranked_2nd.shape[0]} –ª—É—á—à–∏—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤.")
        if st.session_state["computed"]:
            if mode == str(Mode.PROF):
                nan_mask = np.delete(nan_mask, [1, 2, 5])
            st.subheader("–ö–∞–Ω–¥–∏–¥–∞—Ç—ã", divider="blue")
            for key in data_cv:
                col1_results, col2_cv = st.columns(2)
                if mode == str(Mode.PROF):
                    key_ = data_cv[key]["–î–æ–ª–∂–Ω–æ—Å—Ç—å"]
                    if "(" in key and ")" not in key:
                        key_ += ")"
                else:
                    key_ = ""
                key_ += f" ({round(data_cv[key]['sim_score_second'] * 100)}% match)"
                key_ = key + f" - {key_}"
                with st.expander(key_):
                    if mode == str(Mode.MASS):
                        url = f"https://www.avito.ru{data_cv[key]['link']}"
                        st.write(f"[–°—Å—ã–ª–∫–∞ –Ω–∞ Avito]({url})")
                    match_score_first = round(data_cv[key]["sim_score_first"] * 100)
                    accent_color = select_color(match_score_first)
                    st.markdown(
                        f"–ü–µ—Ä–≤–∞—è —Ñ–∞–∑–∞: :{accent_color}[{match_score_first}% match]"
                    )

                    match_score_second = round(data_cv[key]["sim_score_second"] * 100)
                    accent_color = select_color(match_score_second)
                    st.markdown(
                        f"–í—Ç–æ—Ä–∞—è —Ñ–∞–∑–∞: :{accent_color}[{match_score_second}% match]"
                    )
                    if mode == str(Mode.PROF):
                        match_score_full_desc = round(
                            data_cv[key]["Full_description_sim"] * 100
                        )
                        accent_color = select_color(match_score_second)
                        st.markdown(
                            f"–ü–æ—Ö–æ–∂–µ—Å—Ç—å –ø–æ –ø–æ–ª–Ω–æ–º—É –æ–ø–∏—Å–∞–Ω–∏—é: :{accent_color}[{match_score_full_desc}% match]"
                        )

                    ranking_features = deepcopy(
                        config["model"]["stage_2"]["ranking_features"]
                    )
                    if mode == str(Mode.PROF):
                        ranking_features.remove("–î–æ–ª–∂–Ω–æ—Å—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—è")
                        ranking_features.remove("–î–æ–ª–∂–Ω–æ—Å—Ç—å –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è")
                        ranking_features.remove("Full_description")
                        job_labels = [
                            "–î–æ–ª–∂–Ω–æ—Å—Ç—å_sim",
                            "–î–æ–ª–∂–Ω–æ—Å—Ç—å_cat_sim",
                            "–î–æ–ª–∂–Ω–æ—Å—Ç—å_subcat_sim",
                        ]
                        data_cv[key]["–î–æ–ª–∂–Ω–æ—Å—Ç—å_sim"] = (
                            sum([data_cv[key][job_label] for job_label in job_labels])
                            / 3
                        )
                    # else:
                    #     ranking_features.remove("date")
                    for i, feature in enumerate(ranking_features):
                        col_results_1, col_results_2, col_results_3 = st.columns(
                            [2, 1, 2], gap="small", vertical_alignment="center"
                        )
                        num_rows = (
                            max(len(data_cv[key][feature]), len(vacancy_prep[feature]))
                            / 20
                        )
                        container_height = round(num_rows * 30) + 60
                        with col_results_1:
                            if i == 0:
                                st.header("–ö–∞–Ω–¥–∏–¥–∞—Ç")
                            container_cv = st.container(
                                border=True, height=container_height
                            )
                            feature_print = feature
                            if feature in map_names:
                                feature_print = map_names[feature]
                            container_cv.caption(feature_print)
                            if feature == "–ê–¥—Ä–µ—Å":
                                formated_text = format_intersection(
                                    vacancy_prep[feature],
                                    data_cv[key]["–ê–¥—Ä–µ—Å"],
                                )
                            else:
                                formated_text = format_intersection(
                                    vacancy_prep[feature],
                                    data_cv[key][feature],
                                )
                            container_cv.markdown(formated_text.capitalize())

                        with col_results_2:
                            if i == 0:
                                st.header(" ")
                            container_score = st.container(
                                border=True, height=container_height
                            )
                            match_score = round(data_cv[key][f"{feature}_sim"] * 100)
                            flag_vac = False
                            flag_cv = False
                            if nan_mask[i] == 0:
                                match_score = 0
                                flag_vac = True
                            if data_cv[key][feature].lower() in [
                                "–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö",
                                "–Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏",
                                "",
                                "none",
                                "–Ω–µ —É–∫–∞–∑–∞–Ω–æ",
                                "–Ω–µ —É–∫–∞–∑–∞–Ω–∞",
                                "–Ω–µ —É–∫–∞–∑–∞–Ω",
                                "–Ω–µ –∑–∞–¥–∞–Ω",
                            ]:
                                match_score = 0
                                flag_cv = True
                            if flag_vac * flag_cv:
                                match_score = 0
                            accent_color = select_color(match_score)
                            container_score.markdown(
                                "<br>" * int((num_rows // 2)), unsafe_allow_html=True
                            )
                            if feature == "–ê–¥—Ä–µ—Å":
                                container_score.markdown(
                                    f":{accent_color}[{match_score}%\n –±–ª–∏–∑–æ—Å—Ç—å]"
                                )
                            else:
                                if flag_vac:
                                    container_score.markdown(
                                        "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"
                                    )
                                else:
                                    container_score.markdown(
                                        f":{accent_color}[{match_score}%\nmatch]"
                                    )

                        with col_results_3:
                            if i == 0:
                                st.header("–í–∞–∫–∞–Ω—Å–∏—è")
                            container_vac = st.container(
                                border=True, height=container_height
                            )
                            feature_print = feature
                            if feature in map_names:
                                feature_print = map_names[feature]
                            container_vac.caption(feature_print)
                            if feature == "–ê–¥—Ä–µ—Å":
                                formated_text = format_intersection(
                                    data_cv[key]["–ê–¥—Ä–µ—Å"], vacancy_prep[feature]
                                )
                            else:
                                formated_text = format_intersection(
                                    data_cv[key][feature], vacancy_prep[feature]
                                )
                            container_vac.markdown(formated_text.capitalize())
                        # if feature == "–î–æ–ª–∂–Ω–æ—Å—Ç—å":
                        #     st.info(
                        #         "–£–∫–∞–∑–∞–Ω–æ —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ 3 —Å–∫–æ—Ä–æ–≤ –¥–ª—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å –î–æ–ª–∂–Ω–æ—Å—Ç—å—é.",
                        #         icon="‚ÑπÔ∏è",
                        #     )
                        # if feature == "–ê–¥—Ä–µ—Å":
                        #     st.info(
                        #         "100% –±–ª–∏–∑–æ—Å—Ç—å –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –∫–∞–Ω–¥–∏–¥–∞—Ç –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –±–ª–∏–∂–µ –≤—Å–µ—Ö –¥—Ä—É–≥–∏—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤",
                        #         icon="‚ÑπÔ∏è",
                        #     )
                        if i < len(ranking_features) - 1:
                            st.divider()
    else:
        st.error(
            "–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –¥–ª—è –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è: '–î–æ–ª–∂–Ω–æ—Å—Ç—å', '–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è', '–õ–æ–∫–∞—Ü–∏—è –∏ —Ñ–æ—Ä–º–∞—Ç —Ä–∞–±–æ—Ç—ã'",
            icon="üö®",
        )
