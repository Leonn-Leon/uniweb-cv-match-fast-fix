import json
from copy import deepcopy
from pathlib import Path

import numpy as np
import pandas as pd
import streamlit as st

from utils.hardcode_data import candidate_names, map_names
from utils.utils import *
import datetime
from loguru import logger

if "computed" not in st.session_state:
    st.session_state["computed"] = False

if "vahta_mode" not in st.session_state:
    st.session_state["vahta_mode"] = False # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –≥–∞–ª–æ—á–∫–∞

if "distance_option" not in st.session_state:
    st.session_state["distance_option"] = "–ù–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π"

st.title("–ú–∞—Å—Å–æ–≤—ã–π –ø–æ–¥–±–æ—Ä –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ üíº")

# mode = st.select_slider(
#     "–í—ã–±–µ—Ä–µ—Ç–µ —Ç–∏–ø –ø–æ–¥–±–æ—Ä–∞",
#     options=[
#         str(Mode.MASS),
#         str(Mode.PROF),
#     ],
# )

mode = Mode.MASS

if mode == str(Mode.PROF):
    vacancy_df = load_data(path="./data/vacancies.csv")
    selector, config = load_model(config_path="./config/config.yaml")
else:
    # vacancy_df = load_data(path="./data_mass/vacancies.csv")
    selector, config = load_model(config_path="./config/config_mass.yaml")

# vacancies = vacancy_df["–î–æ–ª–∂–Ω–æ—Å—Ç—å"].to_list()

if "df_weights" not in st.session_state:
    features = deepcopy(config["model"]["stage_2"]["ranking_features"])
    info_dict = {"–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∞": [], "–í–µ—Å": []}
    for feature, value in zip(features, config["model"]["stage_2"]["weights"]):
        info_dict["–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∞"].append(
            feature if feature not in map_names else map_names[feature]
        )
        info_dict["–í–µ—Å"].append(round(value, 2))

    df_weights = pd.DataFrame(info_dict)
    st.session_state["df_weights"] = df_weights
if 'current_threshold' not in st.session_state:
    st.session_state['current_threshold'] = config["model"]["stage_2"]["score_threshold"]


def update_address_weight_callback():
    """–û–±–Ω–æ–≤–ª—è–µ—Ç –≤–µ—Å '–ê–¥—Ä–µ—Å' –≤ df_weights –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥–∞–ª–æ—á–∫–∏ '–í–∞—Ö—Ç–∞'."""
    try:
        df = st.session_state["df_weights"]
        is_vahta = st.session_state["vahta_mode"] # –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –≥–∞–ª–æ—á–∫–∏

        # –ù–∞—Ö–æ–¥–∏–º –∏–Ω–¥–µ–∫—Å —Å—Ç—Ä–æ–∫–∏ '–ê–¥—Ä–µ—Å'
        address_index_list = df.index[df['–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∞'] == '–ê–¥—Ä–µ—Å'].tolist()

        if not address_index_list:
            # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∏ '–ê–¥—Ä–µ—Å' –Ω–µ—Ç, –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º
            return

        address_index = address_index_list[0]
        current_weight = df.loc[address_index, '–í–µ—Å']

        if is_vahta:
            # –ì–∞–ª–æ—á–∫–∞ –í–ö–õ–Æ–ß–ï–ù–ê
            # –ï—Å–ª–∏ –≤–µ—Å –µ—â–µ –Ω–µ 0, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –µ–≥–æ –∫–∞–∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∏ —Å—Ç–∞–≤–∏–º 0
            if current_weight != 0.0:
                st.session_state.original_address_weight = current_weight
                df.loc[address_index, '–í–µ—Å'] = 0.0
                st.toast("–í–µ—Å '–ê–¥—Ä–µ—Å' —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ 0 (–í–∞—Ö—Ç–∞).", icon="‚ö†Ô∏è") # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ

        else:
            # –ì–∞–ª–æ—á–∫–∞ –í–´–ö–õ–Æ–ß–ï–ù–ê
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –≤–µ—Å, –µ—Å–ª–∏ –æ–Ω –±—ã–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω
            if st.session_state.original_address_weight is not None:
                # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ç–µ–∫—É—â–∏–π –≤–µ—Å 0 (—á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å —Ä—É—á–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è)
                if current_weight == 0.0:
                     df.loc[address_index, '–í–µ—Å'] = st.session_state.original_address_weight
                     st.toast(f"–í–µ—Å '–ê–¥—Ä–µ—Å' –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {st.session_state.original_address_weight}", icon="üëç")

            # –ï—Å–ª–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –≤–µ—Å –Ω–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω (–º–∞–ª–æ–≤–µ—Ä–æ—è—Ç–Ω–æ), –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º

        # –û–±–Ω–æ–≤–ª—è–µ–º DataFrame –≤ session_state, —á—Ç–æ–±—ã data_editor –ø–µ—Ä–µ—Ä–∏—Å–æ–≤–∞–ª—Å—è
        st.session_state["df_weights"] = df

    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –≤–µ—Å–∞ '–ê–¥—Ä–µ—Å': {e}")

with st.sidebar:
    st.header("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è ‚ÑπÔ∏è")
    st.write("–í–µ—Å–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç —Å–∫–æ—Ä–∏–Ω–≥–∞.")

    st.checkbox(
        "–í–∞—Ö—Ç–∞",
        key="vahta_mode",
        on_change=update_address_weight_callback 
        )

    st.session_state["df_weights"] = st.data_editor(
        st.session_state["df_weights"],
        disabled=["–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∞"],
        hide_index=True,
        # height=423,
        width=300,
    )
    st.divider() 

    # Add threshold controls
    st.header("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–¥–±–æ—Ä–∞")

    # –ü–æ–ª—É—á–∞–µ–º –¥–∞—Ç—É –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
    default_date_str = config["model"]["stage_1"]["date_threshold"]
    try:
        # –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å —Å—Ç—Ä–æ–∫—É –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ –≤ –æ–±—ä–µ–∫—Ç –¥–∞—Ç—ã
        default_date = datetime.date.fromisoformat(default_date_str)
    except ValueError:
        # –ï—Å–ª–∏ —Ñ–æ—Ä–º–∞—Ç –Ω–µ–≤–µ—Ä–Ω—ã–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–ø–∞—Å–Ω—É—é –¥–∞—Ç—É
        logger.warning(f"Invalid date format in config for date_threshold: '{default_date_str}'. Using 2025-02-01.")
        default_date = datetime.date(2025, 2, 1)

    # –°–æ–∑–¥–∞–µ–º –≤–∏–¥–∂–µ—Ç –¥–ª—è –≤—ã–±–æ—Ä–∞ –¥–∞—Ç—ã
    selected_date_threshold = st.date_input(
        "–†–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å —Ä–µ–∑—é–º–µ –Ω–µ —Å—Ç–∞—Ä—à–µ:",
        value=default_date,
        min_value=datetime.date(2015, 1, 1),
        max_value=datetime.date.today(),
        help="–†–µ–∑—é–º–µ, –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–µ –∏–ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–æ —ç—Ç–æ–π –¥–∞—Ç—ã, –±—É–¥—É—Ç –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã."
    )

    threshold = st.slider(
        "–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ–Ω—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è",
        min_value=0.0,
        max_value=1.0,
        value=0.5,
        step=0.05,
        help="–ö–∞–Ω–¥–∏–¥–∞—Ç—ã —Å –ø—Ä–æ—Ü–µ–Ω—Ç–æ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –Ω–∏–∂–µ —ç—Ç–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–µ –±—É–¥—É—Ç –ø–æ–∫–∞–∑–∞–Ω—ã"
    )

    # st.radio(
    #     "–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é (–∫–º):",
    #     options=["–ù–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π", "100", "500", "1000", "5000"], # –î–æ—Å—Ç—É–ø–Ω—ã–µ –æ–ø—Ü–∏–∏
    #     key="distance_option", # –°–≤—è–∑—ã–≤–∞–µ–º —Å —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º —Å–µ—Å—Å–∏–∏
    #     horizontal=True, # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ
    #     help="–§–∏–ª—å—Ç—Ä—É–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –Ω–∞ 1-–º —ç—Ç–∞–ø–µ –ø–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é –¥–æ –≤–∞–∫–∞–Ω—Å–∏–∏."
    # )

    st.selectbox(
        label="–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é (–∫–º):",
        options=["–ù–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π", "100", "500", "1000", "5000"], # –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –æ–ø—Ü–∏–π
        key="distance_option", # –°–≤—è–∑—ã–≤–∞–µ–º —Å —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º —Å–µ—Å—Å–∏–∏
        # index=distance_options.index(st.session_state.distance_option), # –ú–æ–∂–Ω–æ –∑–∞–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        help="–§–∏–ª—å—Ç—Ä—É–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –Ω–∞ 1-–º —ç—Ç–∞–ø–µ –ø–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é –¥–æ –≤–∞–∫–∞–Ω—Å–∏–∏."
    )

    # Add apply button for threshold
    # if st.button("–ü—Ä–∏–º–µ–Ω–∏—Ç—å –ø–æ—Ä–æ–≥", key="apply_threshold"):
    #     st.session_state['current_threshold'] = threshold
    #     st.rerun()

vacancy = {}
placeholder_position = "–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä, ¬´–ì–æ—Ä–Ω–æ—Ä–∞–±–æ—á–∏–π¬ª."
vacancy["–î–æ–ª–∂–Ω–æ—Å—Ç—å"] = st.text_input(
    "–î–æ–ª–∂–Ω–æ—Å—Ç—å",
    placeholder=placeholder_position,
    value="",
    help=placeholder_position,
)
vacancy["–î–æ–ª–∂–Ω–æ—Å—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—è"] = vacancy["–î–æ–ª–∂–Ω–æ—Å—Ç—å"]
vacancy["–î–æ–ª–∂–Ω–æ—Å—Ç—å –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è"] = vacancy["–î–æ–ª–∂–Ω–æ—Å—Ç—å"]
placeholder_req = "–ü–µ—Ä–µ—á–∏—Å–ª–∏—Ç–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –∫–∞–Ω–¥–∏–¥–∞—Ç—É, –Ω–∞–ø—Ä–∏–º–µ—Ä ,—É—Ä–æ–≤–µ–Ω—å –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –∏ –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—ã–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏, –æ–±—ä–µ–º –æ–ø—ã—Ç–∞ —Ä–∞–±–æ—Ç—ã, —Ñ–∏–∑–∏—á–µ—Å–∫–∏–µ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã –∏ —Ç–¥."
vacancy["required"] = st.text_area(
    "–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è",
    placeholder=placeholder_req,
    value="",
    help=placeholder_req,
)
placeholder_loc = "–£–∫–∞–∂–∏—Ç–µ –∞–¥—Ä–µ—Å –æ—Å—É—â–µ—Å—Ç–≤–ª–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã, —Ç–∏–ø –∑–∞–Ω—è—Ç–æ—Å—Ç–∏ (–≤–∞—Ö—Ç–æ–≤—ã–π –º–µ—Ç–æ–¥, –ø–æ–ª–Ω–∞—è –∑–∞–Ω—è—Ç–æ—Å—Ç—å, —á–∞—Å—Ç–∏—á–Ω–∞—è –∑–∞–Ω—è—Ç–æ—Å—Ç—å –∏ –¥—Ä.), –∞ —Ç–∞–∫–∂–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –ø–µ—Ä–µ–µ–∑–¥–∞."
vacancy["location"] = st.text_area(
    "–õ–æ–∫–∞—Ü–∏—è –∏ —Ñ–æ—Ä–º–∞—Ç —Ä–∞–±–æ—Ç—ã",
    placeholder=placeholder_loc,
    value="",
    help=placeholder_loc,
)
placeholder_add = "–ü–µ—Ä–µ—á–∏—Å–ª–∏—Ç–µ –Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –∫–∞–Ω–¥–∏–¥–∞—Ç—É, –Ω–∞–ø—Ä–∏–º–µ—Ä, —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –Ω–∞–≤—ã–∫–∏, –æ–ø–∏—Å–∞–Ω–∏–µ –æ–ø—ã—Ç–∞ —Ä–∞–±–æ—Ç—ã, –¥—Ä—É–≥–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞."
vacancy["additional"] = st.text_area(
    "–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è",
    placeholder=placeholder_add,
    value="",
    help=placeholder_add,
)
# salary_feats = st.text_area("–£—Ä–æ–≤–µ–Ω—å –∑–∞—Ä–∞–±–æ—Ç–Ω–æ–π –ø–ª–∞—Ç—ã", placeholder="–í–≤–µ–¥–∏—Ç–µ –∑–∞—Ä–ø–ª–∞—Ç–Ω—É—é –≤–∏–ª–∫—É", value = None)

if st.button("–ü–æ–¥–æ–±—Ä–∞—Ç—å", type="primary"):
    if (
        vacancy["–î–æ–ª–∂–Ω–æ—Å—Ç—å"] != ""
        and vacancy["required"] != ""
        and vacancy["location"] != ""
    ):
        if mode == str(Mode.PROF):
            pass
        else:
            df_cv = load_data(f"./data_mass/candidates_new.csv")
            df_cv = df_cv.rename(columns={"address": "–ê–¥—Ä–µ—Å"})
        with st.status("–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–∏..."):
            vacancy = selector.preprocess_vacancy(vacancy)
        with st.status("–ü–æ–¥–±–æ—Ä –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤..."):
            if (
                not Path("./tmp_cvs.csv").exists()
                or config["general"]["mode"] == "prod"
            ):
                st.write(f"–ü–µ—Ä–≤–∞—è —Ñ–∞–∑–∞: –∞–Ω–∞–ª–∏–∑ {df_cv.shape[0]} –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤..")
                
                ############### –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é ###############
                selected_option = st.session_state.get("distance_option", "–ù–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π")
                max_distance_filter = None

                if selected_option != "–ù–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π":
                    max_distance_filter = float(selected_option)

                ############### –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–ª–∞—à–∫–∏ –í–ê–•–¢–´ ###############
                # –°–æ—Å—Ç–æ—è–Ω–∏–µ –≥–∞–ª–æ—á–∫–∏ "–í–∞—Ö—Ç–∞"
                is_vahta = st.session_state.get("vahta_mode", False)
                
                save_first_stage_weights = config["model"]["stage_1"]["weights"]
                if is_vahta:
                    # –ï—Å–ª–∏ –≥–∞–ª–æ—á–∫–∞ –≤–∫–ª—é—á–µ–Ω–∞, —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤–µ—Å "–ê–¥—Ä–µ—Å" –≤ 0
                    save_first_stage_weights[1] = 0.0

                df_ranked_1st = selector.rank_first_stage(
                    vacancy=vacancy, df_relevant=df_cv.copy(),
                    date_threshold=selected_date_threshold, is_vahta=is_vahta, max_distance_filter=max_distance_filter,
                    first_stage_weights=np.array(save_first_stage_weights),
                )
                st.write(f"–í—Ç–æ—Ä–∞—è —Ñ–∞–∑–∞: –∞–Ω–∞–ª–∏–∑ {df_ranked_1st.shape[0]} –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤..")

                df_ranked_2nd, vacancy_prep, nan_mask = selector.rank_second_stage(
                    vacancy=vacancy,
                    df_relevant=df_ranked_1st.copy(),
                    df_weights=st.session_state["df_weights"],
                    score_threshold_stage_2=threshold
                )
                if config["general"]["mode"] != "prod":
                    df_ranked_2nd.to_csv("./tmp_cvs.csv", index=False)
                    with open("./tmp_vac.json", "w") as f:
                        json.dump(vacancy_prep, f, ensure_ascii=False)
                    np.save("./tmp_mask.npy", nan_mask)
            else:
                df_ranked_2nd = pd.read_csv("./tmp_cvs.csv")
                with open("./tmp_vac.json", "r") as f:
                    vacancy_prep = json.load(f)
                nan_mask = np.load("./tmp_mask.npy")

            data_cv = df2dict(df_ranked_2nd)
            st.session_state["computed"] = True
            st.write(f"–í—ã–±—Ä–∞–Ω–æ {df_ranked_2nd.shape[0]} –ª—É—á—à–∏—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤.")
        if st.session_state["computed"]:
            if mode == str(Mode.PROF):
                nan_mask = np.delete(nan_mask, [1, 2, 5])
            st.subheader("–ö–∞–Ω–¥–∏–¥–∞—Ç—ã", divider="blue")
            for key in data_cv:
                col1_results, col2_cv = st.columns(2)
                key_ = data_cv[key]["–î–æ–ª–∂–Ω–æ—Å—Ç—å"]
                if "(" in key and ")" not in key:
                    key_ += ")"
                key_ += f" ({round(data_cv[key]['sim_score_second'] * 100)}% match)"
                key_ = key + f" - {key_}"
                with st.expander(key_):
                    if mode == str(Mode.MASS):
                        url = f"https://www.avito.ru{data_cv[key]['link']}"
                        st.write(f"[–°—Å—ã–ª–∫–∞ –Ω–∞ Avito]({url})")
                    match_score_first = round(data_cv[key]["sim_score_first"] * 100)
                    accent_color = select_color(match_score_first)
                    st.markdown(
                        f"–ü–µ—Ä–≤–∞—è —Ñ–∞–∑–∞: :{accent_color}[{match_score_first}% match]"
                    )

                    match_score_second = round(data_cv[key]["sim_score_second"] * 100)
                    accent_color = select_color(match_score_second)
                    st.markdown(
                        f"–í—Ç–æ—Ä–∞—è —Ñ–∞–∑–∞: :{accent_color}[{match_score_second}% match]"
                    )
                    if mode == str(Mode.PROF):
                        match_score_full_desc = round(
                            data_cv[key]["Full_description_sim"] * 100
                        )
                        accent_color = select_color(match_score_second)
                        st.markdown(
                            f"–ü–æ—Ö–æ–∂–µ—Å—Ç—å –ø–æ –ø–æ–ª–Ω–æ–º—É –æ–ø–∏—Å–∞–Ω–∏—é: :{accent_color}[{match_score_full_desc}% match]"
                        )

                    ranking_features = deepcopy(
                        config["model"]["stage_2"]["ranking_features"]
                    )
                    if mode == str(Mode.PROF):
                        ranking_features.remove("–î–æ–ª–∂–Ω–æ—Å—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—è")
                        ranking_features.remove("–î–æ–ª–∂–Ω–æ—Å—Ç—å –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è")
                        ranking_features.remove("Full_description")
                        job_labels = [
                            "–î–æ–ª–∂–Ω–æ—Å—Ç—å_sim",
                            "–î–æ–ª–∂–Ω–æ—Å—Ç—å_cat_sim",
                            "–î–æ–ª–∂–Ω–æ—Å—Ç—å_subcat_sim",
                        ]
                        data_cv[key]["–î–æ–ª–∂–Ω–æ—Å—Ç—å_sim"] = (
                            sum([data_cv[key][job_label] for job_label in job_labels])
                            / 3
                        )
                    # else:
                    #     ranking_features.remove("date")
                    for i, feature in enumerate(ranking_features):
                        col_results_1, col_results_2, col_results_3 = st.columns(
                            [2, 1, 2], gap="small", vertical_alignment="center"
                        )
                        num_rows = (
                            max(len(data_cv[key][feature]), len(vacancy_prep[feature]))
                            / 20
                        )
                        container_height = round(num_rows * 30) + 60
                        with col_results_1:
                            if i == 0:
                                st.header("–ö–∞–Ω–¥–∏–¥–∞—Ç")
                            container_cv = st.container(
                                border=True, height=container_height
                            )
                            feature_print = feature
                            if feature in map_names:
                                feature_print = map_names[feature]
                            container_cv.caption(feature_print)
                            if feature == "–ê–¥—Ä–µ—Å":
                                formated_text = format_intersection(
                                    vacancy_prep[feature],
                                    data_cv[key]["–ê–¥—Ä–µ—Å"],
                                )
                            else:
                                formated_text = format_intersection(
                                    vacancy_prep[feature],
                                    data_cv[key][feature],
                                )
                            container_cv.markdown(formated_text.capitalize())

                        with col_results_2:
                            if i == 0:
                                st.header(" ")
                            container_score = st.container(
                                border=True, height=container_height
                            )
                            match_score = round(data_cv[key][f"{feature}_sim"] * 100)
                            flag_vac = False
                            flag_cv = False
                            if nan_mask[i] == 0:
                                match_score = 0
                                flag_vac = True
                            if data_cv[key][feature].lower() in [
                                "–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö",
                                "–Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏",
                                "",
                                "none",
                                "–Ω–µ —É–∫–∞–∑–∞–Ω–æ",
                                "–Ω–µ —É–∫–∞–∑–∞–Ω–∞",
                                "–Ω–µ —É–∫–∞–∑–∞–Ω",
                                "–Ω–µ –∑–∞–¥–∞–Ω",
                            ]:
                                match_score = 0
                                flag_cv = True
                            if flag_vac * flag_cv:
                                match_score = 0
                            accent_color = select_color(match_score)
                            container_score.markdown(
                                "<br>" * int((num_rows // 2)), unsafe_allow_html=True
                            )
                            if feature == "–ê–¥—Ä–µ—Å":
                                container_score.markdown(
                                    f":{accent_color}[{match_score}%\n –±–ª–∏–∑–æ—Å—Ç—å]"
                                )
                            else:
                                if flag_vac:
                                    container_score.markdown(
                                        "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"
                                    )
                                else:
                                    container_score.markdown(
                                        f":{accent_color}[{match_score}%\nmatch]"
                                    )

                        with col_results_3:
                            if i == 0:
                                st.header("–í–∞–∫–∞–Ω—Å–∏—è")
                            container_vac = st.container(
                                border=True, height=container_height
                            )
                            feature_print = feature
                            if feature in map_names:
                                feature_print = map_names[feature]
                            container_vac.caption(feature_print)
                            if feature == "–ê–¥—Ä–µ—Å":
                                formated_text = format_intersection(
                                    data_cv[key]["–ê–¥—Ä–µ—Å"], vacancy_prep[feature]
                                )
                            else:
                                formated_text = format_intersection(
                                    data_cv[key][feature], vacancy_prep[feature]
                                )
                            container_vac.markdown(formated_text.capitalize())
                        if i < len(ranking_features) - 1:
                            st.divider()
    else:
        st.error(
            "–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –¥–ª—è –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è: '–î–æ–ª–∂–Ω–æ—Å—Ç—å', '–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è', '–õ–æ–∫–∞—Ü–∏—è –∏ —Ñ–æ—Ä–º–∞—Ç —Ä–∞–±–æ—Ç—ã'",
            icon="üö®",
        )
